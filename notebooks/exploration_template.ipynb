{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dragon's Codex - Data Exploration Notebook\n",
    "\n",
    "**Week 1, Session 3**: Testing markdown parsing and data extraction\n",
    "\n",
    "This notebook tests:\n",
    "1. Book markdown parsing\n",
    "2. Chapter extraction\n",
    "3. Wiki temporal section parsing\n",
    "4. Glossary extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports successful!\n",
      "✓ Project root: C:\\Users\\victor.diaz\\Documents\\_AI\\dragon-codex\n",
      "✓ Books path: C:\\Users\\victor.diaz\\Documents\\_AI\\dragon-codex\\data\\raw\\books\n",
      "✓ Wiki path: C:\\Users\\victor.diaz\\Documents\\_AI\\dragon-codex\\data\\raw\\wiki\n"
     ]
    }
   ],
   "source": [
    "# Test imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Test our utilities\n",
    "from utils.config import Config\n",
    "from utils.logger import setup_logging, get_logger\n",
    "from utils.wot_constants import BOOK_TITLES, get_book_number\n",
    "\n",
    "# Setup\n",
    "config = Config()\n",
    "logger = get_logger(__name__)\n",
    "\n",
    "print(\"✓ All imports successful!\")\n",
    "print(f\"✓ Project root: {config.PROJECT_ROOT}\")\n",
    "print(f\"✓ Books path: {config.BOOKS_PATH}\")\n",
    "print(f\"✓ Wiki path: {config.WIKI_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Book Parsing Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: 01-The_Eye_of_the_World.txt\n",
      "✓ Loaded 1,677,243 characters\n",
      "\n",
      "First 500 characters:\n",
      "------------------------------------------------------------\n",
      "PROLOGUE\n",
      "\n",
      " \n",
      "\n",
      "*Dragonmount*\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "The palace still shook occasionally as the earth rumbled in memory, groaned as if it would deny what had happened. Bars of sunlight cast through rents in the walls made motes of dust glitter where they yet hung in the air. Scorch-marks marred the walls, the floors, the ceilings. Broad black smears crossed the blistered paints and gilt of once-bright murals, soot overlaying crumbling friezes of men and animals which seemed to have attempted to walk before the mad\n"
     ]
    }
   ],
   "source": [
    "# Load Book 1 (Eye of the World)\n",
    "books_dir = Path(config.BOOKS_PATH)\n",
    "\n",
    "# Find first book file (might be .md or .txt)\n",
    "book_files = list(books_dir.glob('*Eye*.md')) + list(books_dir.glob('*Eye*.txt'))\n",
    "if not book_files:\n",
    "    book_files = sorted(list(books_dir.glob('*.md')) + list(books_dir.glob('*.txt')))\n",
    "\n",
    "book_file = book_files[0]\n",
    "print(f\"Loading: {book_file.name}\")\n",
    "\n",
    "# Read content\n",
    "with open(book_file, 'r', encoding='utf-8') as f:\n",
    "    book_content = f.read()\n",
    "\n",
    "print(f\"✓ Loaded {len(book_content):,} characters\")\n",
    "print(f\"\\nFirst 500 characters:\")\n",
    "print(\"-\" * 60)\n",
    "print(book_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prologue found: 0\n",
      "\n",
      "Chapters found: 0\n",
      "\n",
      "Epilogue found: 0\n",
      "\n",
      "✓ Total sections: 0\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import sys\n",
    "\n",
    "# Assuming the script is run with the filename as argument, or hardcode it\n",
    "if len(sys.argv) > 1:\n",
    "    filename = sys.argv[1]\n",
    "else:\n",
    "    filename = '01-The Eye of the World - Robert Jordan-sample.txt'\n",
    "\n",
    "# Parse book number and name from filename\n",
    "book_parts = filename.split('-', 1)\n",
    "book_number = book_parts[0].strip()\n",
    "if len(book_parts) > 1:\n",
    "    book_name = book_parts[1].rstrip('.txt').strip()\n",
    "else:\n",
    "    book_name = ''\n",
    "\n",
    "# Read the file\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Initialize structures\n",
    "data = {\n",
    "    \"book_number\": book_number,\n",
    "    \"book_name\": book_name,\n",
    "    \"chapters\": [],\n",
    "    \"glossary\": []\n",
    "}\n",
    "\n",
    "current_section = None\n",
    "current_chapter = None\n",
    "chapter_content = []\n",
    "glossary_lines = []\n",
    "\n",
    "i = 0\n",
    "while i < len(lines):\n",
    "    line = lines[i]\n",
    "    stripped = line.strip()\n",
    "\n",
    "    if stripped == \"PROLOGUE\":\n",
    "        current_section = \"chapter\"\n",
    "        chapter_num = 0\n",
    "        current_chapter = {\"number\": chapter_num, \"title\": \"\", \"content\": \"\"}\n",
    "        i += 1\n",
    "        # Skip blank lines to title\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            current_chapter[\"title\"] = lines[i].strip().strip('*')\n",
    "        i += 1\n",
    "        # Skip blank lines to content\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1\n",
    "        continue\n",
    "\n",
    "    elif stripped == \"CHAPTER\":\n",
    "        if current_section == \"chapter\" and current_chapter:\n",
    "            current_chapter[\"content\"] = ''.join(chapter_content).strip()\n",
    "            data[\"chapters\"].append(current_chapter)\n",
    "            chapter_content = []\n",
    "\n",
    "        i += 1\n",
    "        # Skip blank lines to number\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1\n",
    "        chapter_num = 0\n",
    "        if i < len(lines):\n",
    "            try:\n",
    "                chapter_num = int(lines[i].strip())\n",
    "            except ValueError:\n",
    "                pass\n",
    "        current_chapter = {\"number\": chapter_num, \"title\": \"\", \"content\": \"\"}\n",
    "        i += 1\n",
    "        # Skip blank lines to title\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1\n",
    "        if i < len(lines):\n",
    "            current_chapter[\"title\"] = lines[i].strip().strip('*')\n",
    "        i += 1\n",
    "        # Skip blank lines to content\n",
    "        while i < len(lines) and not lines[i].strip():\n",
    "            i += 1\n",
    "        current_section = \"chapter\"\n",
    "        continue\n",
    "\n",
    "    elif stripped == \"GLOSSARY\":\n",
    "        if current_section == \"chapter\" and current_chapter:\n",
    "            current_chapter[\"content\"] = ''.join(chapter_content).strip()\n",
    "            data[\"chapters\"].append(current_chapter)\n",
    "            chapter_content = []\n",
    "        current_section = \"glossary\"\n",
    "        i += 1\n",
    "        continue\n",
    "\n",
    "    if current_section == \"chapter\":\n",
    "        chapter_content.append(line)\n",
    "    elif current_section == \"glossary\":\n",
    "        glossary_lines.append(line)\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Append the last section\n",
    "if current_section == \"chapter\" and current_chapter:\n",
    "    current_chapter[\"content\"] = ''.join(chapter_content).strip()\n",
    "    data[\"chapters\"].append(current_chapter)\n",
    "elif current_section == \"glossary\":\n",
    "    # Parse glossary\n",
    "    current_term = None\n",
    "    term_description = []\n",
    "    note = []  # Ignore note\n",
    "    for line in glossary_lines:\n",
    "        stripped_line = line.strip()\n",
    "        if stripped_line.startswith('> '):\n",
    "            # New term\n",
    "            if current_term:\n",
    "                current_term[\"description\"] = ''.join(term_description).strip()\n",
    "                data[\"glossary\"].append(current_term)\n",
    "                term_description = []\n",
    "\n",
    "            # Parse the term line\n",
    "            clean_line = line.strip()[2:].replace('*', '').replace('\\\\', '').strip()\n",
    "            term = \"\"\n",
    "            pronunciation = \"\"\n",
    "            desc_start = \"\"\n",
    "\n",
    "            if '(' in clean_line and ')' in clean_line:\n",
    "                match = re.match(r'^(.+?)\\s*\\(([^)]+)\\)\\s*:\\s*(.*)$', clean_line)\n",
    "                if match:\n",
    "                    term = match.group(1).strip()\n",
    "                    pronunciation = match.group(2).strip()\n",
    "                    desc_start = match.group(3).strip()\n",
    "            else:\n",
    "                match = re.match(r'^([^:]+):\\s*(.*)$', clean_line)\n",
    "                if match:\n",
    "                    term = match.group(1).strip()\n",
    "                    pronunciation = \"\"\n",
    "                    desc_start = match.group(2).strip()\n",
    "\n",
    "            if term:\n",
    "                current_term = {\n",
    "                    \"term\": term,\n",
    "                    \"pronunciation\": pronunciation,\n",
    "                }\n",
    "                if desc_start:\n",
    "                    term_description.append(desc_start + '\\n')\n",
    "        else:\n",
    "            if current_term:\n",
    "                term_description.append(line)\n",
    "            else:\n",
    "                note.append(line)  # Ignore\n",
    "\n",
    "    # Append last term\n",
    "    if current_term:\n",
    "        current_term[\"description\"] = ''.join(term_description).strip()\n",
    "        data[\"glossary\"].append(current_term)\n",
    "\n",
    "# Write to JSON\n",
    "output_filename = filename.replace('.txt', '.json')\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(data, f, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"JSON file created: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dragon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
